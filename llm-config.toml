[server]
host = "0.0.0.0"
port = 8000

[models.qwen-vision]
model_path = "/home/bruger/models/Qwen3VL-8B-Instruct-Q8_0.gguf"
mmproj_path = "/home/bruger/models/mmproj-Qwen3VL-8B-Instruct-F16.gguf"
llama_args = ["--port", "${PORT}", "--ctx-size", "8192", "--gpu-layers", "99", "--mlock"]

[models.gemma-chat]
model_path = "/home/bruger/models/gemma-2-2b-it-q8_0.gguf"
llama_args = ["--port", "${PORT}", "--ctx-size", "16384", "--gpu-layers", "99", "--mlock"]