server:
  host: "0.0.0.0"
  port: 8000

models:
  qwen-vision:
    model_path: "/home/bruger/models/Qwen3VL-8B-Instruct-Q8_0.gguf"
    mmproj_path: "/home/bruger/models/mmproj-Qwen3VL-8B-Instruct-F16.gguf"
    llama_args: 
      - "--port"
      - '${PORT}'
      - "--ctx-size"
      - "8192"
      - "--batch-size"
      - "256"
      - "--gpu-layers"
      - "99"
      - "--mlock"
      - "-fa"

  gemma-chat:
    model_path: "/home/bruger/models/gemma-2-2b-it-q8_0.gguf"
    llama_args: 
      - "--port"
      - '${PORT}'
      - "--ctx-size"
      - "16384"
      - "--gpu-layers"
      - "99"
      - "--no-mmap"
      - "--mlock"
      - "-fa"